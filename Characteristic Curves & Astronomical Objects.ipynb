{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn\n",
    "from scipy import linalg\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from gatspy import datasets, periodic\n",
    "import pywt\n",
    "import gc\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.interpolate import UnivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pandas dataframe with training set time-series and metadata\n",
    "\n",
    "train_series = pd.read_csv('training_set.csv')\n",
    "train_series = train_series.sort_values(['object_id', 'passband'], ascending = [True, True])\n",
    "\n",
    "train_metadata = pd.read_csv('training_set_metadata.csv')\n",
    "\n",
    "train_series.head()\n",
    "\n",
    "#print('Classes contained in the data set:')\n",
    "types = train_metadata['target'].unique()\n",
    "#print(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine time series data and merge with metadata\n",
    "\n",
    "#create arrays for object id and passband through which to iterate\n",
    "ids = train_metadata['object_id'].values\n",
    "passbands = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "#append mjd, flux, and flux_err values per passband per object to the metadata\n",
    "for band in passbands:\n",
    "    mjd_column = []\n",
    "    flux_column = []\n",
    "    fluxerr_column = []\n",
    "    for obj in ids:\n",
    "        selection = train_series.loc[(train_series['object_id'] == obj) & (train_series['passband'] == band)]\n",
    "        mjd_column.append(np.array(selection['mjd']))\n",
    "        flux_column.append(np.array(selection['flux']))\n",
    "        fluxerr_column.append(np.array(selection['flux_err']))\n",
    "    train_metadata['mjd_passband_{}'.format(band)] = mjd_column\n",
    "    train_metadata['flux_passband_{}'.format(band)] = flux_column\n",
    "    train_metadata['fluxerr_passband_{}'.format(band)] = fluxerr_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting unneccessary columns for the sake of efficiency\n",
    "#print(train_metadata.columns.values)\n",
    "\n",
    "del train_metadata['ra'], train_metadata['decl'], train_metadata['gal_l'], train_metadata['gal_b'], train_metadata['mwebv']\n",
    "\n",
    "train_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot distribution of object frequency in each class\n",
    "\n",
    "train_metadata['target'].value_counts().plot(kind='bar')\n",
    "plt.title('Training Set Class Frequencies')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of representative objects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot object distributions between survey fields\n",
    "#ddf == 1 means the object comes from the ddf survey area\n",
    "#ddf == 0 means the object comes from the wfd survey area\n",
    "#ddf == 1 fluxes have significantly smaller uncertainties\n",
    "\n",
    "#distribution of classes surveyed in ddf\n",
    "plt.figure()\n",
    "ddf_events = train_metadata[(train_metadata['ddf'] == 1)]\n",
    "ddf_events['target'].value_counts().plot(kind='bar')\n",
    "\n",
    "plt.title('Training Set Class Frequencies (DDF)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of representative objects')\n",
    "\n",
    "#distribution of classes surveyed in wfd\n",
    "plt.figure()\n",
    "wfd_events = train_metadata[(train_metadata['ddf'] == 0)]\n",
    "wfd_events['target'].value_counts().plot(kind='bar')\n",
    "\n",
    "plt.title('Training Set Class Frequencies (WFD)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of representative objects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHAT CAN THIS DISTRIBUTION TELL US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframes for each class represented\n",
    "type_90 = train_metadata.loc[train_metadata['target'] == 90]\n",
    "type_42 = train_metadata.loc[train_metadata['target'] == 42]\n",
    "type_65 = train_metadata.loc[train_metadata['target'] == 65]\n",
    "type_16 = train_metadata.loc[train_metadata['target'] == 16]\n",
    "type_15 = train_metadata.loc[train_metadata['target'] == 15]\n",
    "type_62 = train_metadata.loc[train_metadata['target'] == 62]\n",
    "type_88 = train_metadata.loc[train_metadata['target'] == 88]\n",
    "type_92 = train_metadata.loc[train_metadata['target'] == 92]\n",
    "type_67 = train_metadata.loc[train_metadata['target'] == 67]\n",
    "type_52 = train_metadata.loc[train_metadata['target'] == 52]\n",
    "type_95 = train_metadata.loc[train_metadata['target'] == 95]\n",
    "type_6 = train_metadata.loc[train_metadata['target'] == 6]\n",
    "type_64 = train_metadata.loc[train_metadata['target'] == 64]\n",
    "type_53 = train_metadata.loc[train_metadata['target'] == 53]\n",
    "\n",
    "target_dataframes = [type_90, type_42, type_65, type_16,\n",
    "                    type_15, type_62, type_88, type_92, type_67,\n",
    "                    type_52, type_95, type_6, type_64, type_53]\n",
    "\n",
    "type_90.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box and whisker plots for spectroscopic\n",
    "#and photometric redshift values across classes\n",
    "\n",
    "train_metadata['hostgal_specz']\n",
    "train_metadata['hostgal_photoz']\n",
    "\n",
    "spec_rs = [x['hostgal_specz'] for x in target_dataframes]\n",
    "photo_rs = [x['hostgal_photoz'] for x in target_dataframes]\n",
    "photerr_rs = [x['hostgal_photoz_err'] for x in target_dataframes]\n",
    "labels = [90, 42, 65, 16, 15, 62, 88, 92, 67, 52, 95, 6, 64, 53]\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Spectroscopic Redshift Across Classes')\n",
    "plt.ylabel('Redshift')\n",
    "plt.xlabel('Class')\n",
    "plt.boxplot(spec_rs, labels = labels)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Photometric Redshift Across Classes')\n",
    "plt.ylabel('Redshift')\n",
    "plt.xlabel('Class')\n",
    "plt.boxplot(photo_rs, labels = labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lomb-Scargle Multiband Periodic Fit\n",
    "#will extract features pertaining to periodicity\n",
    "#from the light curves while incorporating the\n",
    "#correlation of light in different passbands\n",
    "#for unevenly sampled data\n",
    "\n",
    "def fit_multiband(obj_id):\n",
    "    #time, flux, flux error, and passband series\n",
    "    t = train_series[train_series['object_id'] == obj_id]['mjd']\n",
    "    f = train_series[train_series['object_id'] == obj_id]['flux']\n",
    "    e = train_series[train_series['object_id'] == obj_id]['flux_err']\n",
    "    b = train_series[train_series['object_id'] == obj_id]['passband']\n",
    "    \n",
    "    #parameterizing and fitting the model\n",
    "    model = periodic.LombScargleMultibandFast(fit_period= True);\n",
    "    \n",
    "    #period range chosen on the assumption that\n",
    "    #the period will be between 2.4 hours and half\n",
    "    #of the observation window\n",
    "    model.optimizer.period_range = (0.1, int((t.max()-t.min())/2));\n",
    "    model.fit(t, f, e, b);\n",
    "    \n",
    "    #accuracy of fit for the model's best predicted period\n",
    "    best_period_score = model.score(model.best_period);\n",
    "    \n",
    "    #returns model, best predicted period, and its fit score\n",
    "    return [model, model.best_period, float(best_period_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discrete Wavelet Transform with PCA\n",
    "#will help to extract dynamic characteristics\n",
    "#of the data with relatively few features\n",
    "\n",
    "#Smoothing spline regression technique to create\n",
    "#evenly-spaced points since wavelet transform\n",
    "#cannot accept two axes of information\n",
    "def interpolate_signal(obj_id, band):\n",
    "    \n",
    "    #selecting time and flux data for the object\n",
    "    t = (train_series.loc[train_series['object_id'] == obj_id][train_series['passband'] == band]['mjd'])\n",
    "    f = (train_series.loc[train_series['object_id'] == obj_id][train_series['passband'] == band]['flux'])\n",
    "    \n",
    "    #cubic univariate spline function generation\n",
    "    #where if loop handles case when there are \n",
    "    #three or less points\n",
    "    if len(t) > 3:\n",
    "        s0 = UnivariateSpline(t, f)\n",
    "    elif len(t) == 3:\n",
    "        s0 = UnivariateSpline(t, f, k=2)\n",
    "    elif len(t) == 2:\n",
    "        s0 = UnivariateSpline(t, f, k=1)\n",
    "    elif len(t) == 1:\n",
    "        s0 = UnivariateSpline(t, f, k=0)\n",
    "    \n",
    "    return s0, t.min(), t.max()\n",
    "\n",
    "#discrete wavelet transform for light curve\n",
    "#in single passband\n",
    "def single_dwt(obj_id, band):\n",
    "    #performing interpolation, selecting grid\n",
    "    #in time (x) upon which to project\n",
    "    interp, tmin, tmax = interpolate_signal(obj_id, band)\n",
    "    x = np.linspace(tmin, tmax, 100) \n",
    "    y0 = interp(x)\n",
    "    \n",
    "    #padding the edges with constant values to\n",
    "    #avoid edge effects from high-dimensional\n",
    "    #wavelet transform\n",
    "    y0 = pywt.pad(y0, 16, 'constant')\n",
    "    \n",
    "    #discrete wavelet transform on two levels using daubechies wavelet\n",
    "    wav = pywt.wavedec(y0, wavelet = 'db1', level = 7)\n",
    "\n",
    "    #concatenating the large-scale and small-scale frequencies detected\n",
    "    wav_coefficients, wav_details = pywt.coeffs_to_array(wav)\n",
    "    \n",
    "    return wav_coefficients\n",
    "\n",
    "#combine all wavelet transforms across all objects\n",
    "def get_dynamic_feats():\n",
    "    #create a new dataframe with ids\n",
    "    dynamic_feats = pd.DataFrame(ids, columns = ['object_id'])\n",
    "    \n",
    "    #populate columns with dwt for each band\n",
    "    dynamic_feats['dwt_0'] = dynamic_feats.apply(lambda row: single_dwt(row['object_id'], 0), axis = 1)\n",
    "    dynamic_feats['dwt_1'] = dynamic_feats.apply(lambda row: single_dwt(row['object_id'], 1), axis = 1)\n",
    "    dynamic_feats['dwt_2'] = dynamic_feats.apply(lambda row: single_dwt(row['object_id'], 2), axis = 1)\n",
    "    dynamic_feats['dwt_3'] = dynamic_feats.apply(lambda row: single_dwt(row['object_id'], 3), axis = 1)\n",
    "    dynamic_feats['dwt_4'] = dynamic_feats.apply(lambda row: single_dwt(row['object_id'], 4), axis = 1)\n",
    "    dynamic_feats['dwt_5'] = dynamic_feats.apply(lambda row: single_dwt(row['object_id'], 5), axis = 1)\n",
    "    \n",
    "    del dynamic_feats['object_id']\n",
    "    \n",
    "    return dynamic_feats\n",
    "\n",
    "#PCA to convert wavelet transform of a\n",
    "#single band to a single feature\n",
    "def covar_PCA(band):\n",
    "    #reshaping the array so that\n",
    "    #the covariance matrix can be applied\n",
    "    oldwav = pd.DataFrame((untransformed['dwt_{}'.format(band)]).tolist())\n",
    "    oldwav = oldwav.values\n",
    "    m, n = oldwav.shape\n",
    "    #centering the data around the mean\n",
    "    #for each coefficient\n",
    "    oldwav -= oldwav.mean(axis = 0)\n",
    "    \n",
    "    #calculating the covariance matrix\n",
    "    covar = np.cov(oldwav, rowvar = False)\n",
    "    #calculating the eigenvalues and eigenvectors\n",
    "    #of the (symmetrical) covariance matrix\n",
    "    evals, evecs = linalg.eigh(covar)\n",
    "    \n",
    "    #sorting eigenvalues in decreasing order\n",
    "    #while keeping indices consistent between\n",
    "    #evals and evecs\n",
    "    idx = np.argsort(evals)[::-1]\n",
    "    evecs = evecs[:, idx]\n",
    "    evals = evals[idx]\n",
    "    #selecting the most important eigenvector\n",
    "    evecs = evecs[:, :1]\n",
    "    \n",
    "    newwav = np.dot(evecs.T, oldwav.T).T\n",
    "    \n",
    "    return newwav #newwav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untransformed = get_dynamic_feats()\n",
    "untransformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata['wav_coeffs_0'] = covar_PCA(0)\n",
    "train_metadata['wav_coeffs_1'] = covar_PCA(1)\n",
    "train_metadata['wav_coeffs_2'] = covar_PCA(2)\n",
    "train_metadata['wav_coeffs_3'] = covar_PCA(3)\n",
    "train_metadata['wav_coeffs_4'] = covar_PCA(4)\n",
    "train_metadata['wav_coeffs_5'] = covar_PCA(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_metadata['target']\n",
    "train_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting features from timeseries\n",
    "\n",
    "#garbage collector is useful as I manipulate\n",
    "#timeseries and metadata to extract features\n",
    "gc.enable() \n",
    "\n",
    "#extracting descriptive statistics about the time series\n",
    "statistical_features = {\n",
    "    'mjd': ['min', 'max', 'size'],\n",
    "    'flux': ['min', 'max', 'mean', 'median', 'std'],\n",
    "    'flux_err': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "    'detected': ['mean']}\n",
    "\n",
    "#simplifying the dataframe\n",
    "train_feat = train_series.groupby(['object_id', 'passband']).agg(statistical_features)\n",
    "new_columns = [k + '_' + agg for k in statistical_features.keys() for agg in statistical_features[k]]\n",
    "train_feat.columns = new_columns\n",
    "\n",
    "#considering the delta of time and flux\n",
    "#for each object in each passband\n",
    "train_feat['mjd_diff'] = train_feat['mjd_max']-train_feat['mjd_min']\n",
    "train_feat['flux_diff'] = train_feat['flux_max']-train_feat['flux_min']\n",
    "del train_feat['mjd_max'], train_feat['mjd_min']\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "#making it so that each object is represented by one row\n",
    "bands = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "#creating the dataframe based on object id\n",
    "rearranged = pd.DataFrame(ids, columns = ['object_id'])\n",
    "\n",
    "for band in bands:\n",
    "    banddata = train_feat.groupby(['passband']).get_group(band)\n",
    "\n",
    "    rearranged['mjd_size_{}'.format(band)] = np.asarray(banddata['mjd_size'])\n",
    "    rearranged['flux_min_{}'.format(band)] = np.asarray(banddata['flux_min'])\n",
    "    rearranged['flux_max_{}'.format(band)] = np.asarray(banddata['flux_max'])\n",
    "    rearranged['flux_mean_{}'.format(band)] = np.asarray(banddata['flux_mean'])\n",
    "    rearranged['flux_median_{}'.format(band)] = np.asarray(banddata['flux_median'])\n",
    "    rearranged['flux_std_{}'.format(band)] = np.asarray(banddata['flux_std'])\n",
    "    rearranged['detected_mean_{}'.format(band)] = np.asarray(banddata['detected_mean'])\n",
    "    rearranged['flux_err_min_{}'.format(band)] = np.asarray(banddata['flux_err_min'])\n",
    "    rearranged['flux_err_max_{}'.format(band)] = np.asarray(banddata['flux_err_max'])\n",
    "    rearranged['flux_err_mean_{}'.format(band)] = np.asarray(banddata['flux_err_mean'])\n",
    "    rearranged['flux_err_median_{}'.format(band)] = np.asarray(banddata['flux_err_median'])\n",
    "    rearranged['flux_err_std_{}'.format(band)] = np.asarray(banddata['flux_err_std'])\n",
    "    rearranged['flux_err_skew_{}'.format(band)] = np.asarray(banddata['flux_err_skew'])\n",
    "    rearranged['mjd_diff_{}'.format(band)] = np.asarray(banddata['mjd_diff'])\n",
    "    rearranged['flux_diff_{}'.format(band)] = np.asarray(banddata['flux_diff'])\n",
    "\n",
    "rearranged['target'] = y    \n",
    "\n",
    "rearranged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THERE ARE LARGE OBSERVATION GAPS DUE TO THE TELESCOPIC SETTINGS. SO THE DATA IS KIND OF SPARSE. BUT WE CAN TRY TO FOLD THE OBJECTS BY PERIOD BECAUSE SOME OBJECTS WILL EXHIBIT BEHAVIORS LIKE THIS. EXAMPLES???\n",
    "\n",
    "NORMAL CLASSIFIERS ASSUME INDEPENDENT EXAMPLES. SINCE THIS IS TIME-SERIES DATA, POINTS THAT ARE CLOSE IN TIME WILL BE CORRELATED. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to create raw light curve plot\n",
    "def raw_curve(obj_id):\n",
    "    \n",
    "    obj_class = int(train_metadata['target'][train_metadata['object_id'] == obj_id])\n",
    "    \n",
    "    u = mpatches.Patch(color = 'red', label = 'u')\n",
    "    g = mpatches.Patch(color = 'orange', label = 'g')\n",
    "    r = mpatches.Patch(color = 'yellow', label = 'r')\n",
    "    i = mpatches.Patch(color = 'green', label = 'i')\n",
    "    z = mpatches.Patch(color = 'blue', label = 'z')\n",
    "    y = mpatches.Patch(color = 'purple', label = 'y')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.legend(handles=[u, g, r, i, z, y])\n",
    "    plt.title('Raw Light Curve: Object {}'.format(obj_id)+ '; Class {}'.format(obj_class))\n",
    "    plt.xlabel('mjd')\n",
    "    plt.ylabel('flux')\n",
    "\n",
    "    plt.scatter(x = np.array(train_metadata['mjd_passband_0'][train_metadata['object_id'] == obj_id])[0], y = np.array(train_metadata['flux_passband_0'][train_metadata['object_id'] == obj_id])[0], color='red')\n",
    "    plt.scatter(x = np.array(train_metadata['mjd_passband_1'][train_metadata['object_id'] == obj_id])[0], y = np.array(train_metadata['flux_passband_1'][train_metadata['object_id'] == obj_id])[0], color='orange')\n",
    "    plt.scatter(x = np.array(train_metadata['mjd_passband_2'][train_metadata['object_id'] == obj_id])[0], y = np.array(train_metadata['flux_passband_2'][train_metadata['object_id'] == obj_id])[0], color='yellow')\n",
    "    plt.scatter(x = np.array(train_metadata['mjd_passband_3'][train_metadata['object_id'] == obj_id])[0], y = np.array(train_metadata['flux_passband_3'][train_metadata['object_id'] == obj_id])[0], color='green')\n",
    "    plt.scatter(x = np.array(train_metadata['mjd_passband_4'][train_metadata['object_id'] == obj_id])[0], y = np.array(train_metadata['flux_passband_4'][train_metadata['object_id'] == obj_id])[0], color='blue')\n",
    "    plt.scatter(x = np.array(train_metadata['mjd_passband_5'][train_metadata['object_id'] == obj_id])[0], y = np.array(train_metadata['flux_passband_5'][train_metadata['object_id'] == obj_id])[0], color='purple')\n",
    "    \n",
    "    return\n",
    "\n",
    "#define function to print phase plot & best periodic fit\n",
    "def phase_curve(obj_id, model, best_period, best_score):\n",
    "    \n",
    "    obj_class = int(train_metadata['target'][train_metadata['object_id'] == obj_id])\n",
    "    \n",
    "    #single phase in each passband\n",
    "    plt.figure()\n",
    "    plt.title('Phase Plot: Object {}'.format(obj_id) + ': Class {}'.format(obj_class))\n",
    "    plt.xlabel('phase')\n",
    "    plt.ylabel('relative flux')\n",
    "    plt.scatter(x = np.array(train_metadata['mjd_passband_0'][train_metadata['object_id'] == obj_id])[0] / (model.best_period) % 1, y = np.array(train_metadata['flux_passband_0'][train_metadata['object_id'] == obj_id])[0], color = 'red')\n",
    "    plt.scatter(x = np.array(train_metadata['mjd_passband_1'][train_metadata['object_id'] == obj_id])[0] / (model.best_period) % 1, y = np.array(train_metadata['flux_passband_1'][train_metadata['object_id'] == obj_id])[0], color = 'orange')\n",
    "    plt.scatter(x = np.array(train_metadata['mjd_passband_2'][train_metadata['object_id'] == obj_id])[0] / (model.best_period) % 1, y = np.array(train_metadata['flux_passband_2'][train_metadata['object_id'] == obj_id])[0], color = 'yellow')\n",
    "    plt.scatter(x = np.array(train_metadata['mjd_passband_3'][train_metadata['object_id'] == obj_id])[0] / (model.best_period) % 1, y = np.array(train_metadata['flux_passband_3'][train_metadata['object_id'] == obj_id])[0], color = 'green')\n",
    "    plt.scatter(x = np.array(train_metadata['mjd_passband_4'][train_metadata['object_id'] == obj_id])[0] / (model.best_period) % 1, y = np.array(train_metadata['flux_passband_4'][train_metadata['object_id'] == obj_id])[0], color = 'blue')\n",
    "    plt.scatter(x = np.array(train_metadata['mjd_passband_5'][train_metadata['object_id'] == obj_id])[0] / (model.best_period) % 1, y = np.array(train_metadata['flux_passband_5'][train_metadata['object_id'] == obj_id])[0], color = 'purple')\n",
    "    \n",
    "    #best periodic fit for each passband\n",
    "    plt.figure()\n",
    "    plt.title('Best Periodic Fit: {}'.format(best_period) + '; Period Score: {}'.format(best_score))\n",
    "    plt.xlabel('phase')\n",
    "    plt.ylabel('relative flux')\n",
    "    yfit = model.predict(np.linspace(0, best_period, 1000), 0)\n",
    "    plt.plot(np.linspace(0, best_period, 1000), yfit, color = 'red')\n",
    "    yfit = model.predict(np.linspace(0, best_period, 1000), 1)\n",
    "    plt.plot(np.linspace(0, best_period, 1000), yfit, color = 'orange')\n",
    "    yfit = model.predict(np.linspace(0, best_period, 1000), 2)\n",
    "    plt.plot(np.linspace(0, best_period, 1000), yfit, color = 'yellow')\n",
    "    yfit = model.predict(np.linspace(0, best_period, 1000), 3)\n",
    "    plt.plot(np.linspace(0, best_period, 1000), yfit, color = 'green')\n",
    "    yfit = model.predict(np.linspace(0, best_period, 1000), 4)\n",
    "    plt.plot(np.linspace(0, best_period, 1000), yfit, color = 'blue')\n",
    "    yfit = model.predict(np.linspace(0, best_period, 1000), 5)\n",
    "    plt.plot(np.linspace(0, best_period, 1000), yfit, color = 'purple')\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate plots and features for a single object\n",
    "\n",
    "def analyze_characteristics(object_id):\n",
    "    raw_curve(object_id)\n",
    "    [model, best_period, best_score] = fit_multiband(object_id)\n",
    "    phase_curve(object_id, model, best_period, best_score)\n",
    "    \n",
    "    return [best_period, best_score]\n",
    "    \n",
    "#calculating the average and standard deviation\n",
    "#of each of the statistical time series features\n",
    "#where is flux typically and how does it vary for\n",
    "#each of these objects? \n",
    "#def ts_by_target(target):\n",
    "#    target_pd = rearranged[rearranged['target'] == target]\n",
    "#    del target_pd['object_id'], target_pd['target']\n",
    "#    feats = target_pd.columns\n",
    "#    avgs = np.array(target_pd.mean(axis = 0))\n",
    "#    stds = np.array(target_pd.std(axis = 0))\n",
    "#    \n",
    "#    df = pd.DataFrame(columns = feats)\n",
    "#    df.loc['avg'] = avgs\n",
    "#    df.loc['std'] = stds\n",
    "#    \n",
    "#    return df\n",
    "    \n",
    "#calculating the average and stardard deviation\n",
    "#of each of the wavelet coefficients\n",
    "def wav_by_target(target):\n",
    "    target_pd = (train_metadata[train_metadata['target'] == target]).iloc[:, -6:]\n",
    "    feats = target_pd.columns\n",
    "    avgs = np.array(target_pd.mean(axis = 0))\n",
    "    stds = np.array(target_pd.std(axis=0))\n",
    "    \n",
    "    df = pd.DataFrame(columns = feats)\n",
    "    df.loc['avg'] = avgs\n",
    "    df.loc['std'] = stds\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_analysis(target):\n",
    "    \n",
    "    metaseries = train_metadata.loc[train_metadata['target'] == target]\n",
    "    ids = (metaseries['object_id'].unique())\n",
    "    \n",
    "    #generate first four examples using the object analysis\n",
    "    analyze_characteristics(ids[0])\n",
    "    analyze_characteristics(ids[1])\n",
    "    analyze_characteristics(ids[2])\n",
    "    analyze_characteristics(ids[3])\n",
    "    \n",
    "    #plot distribution of detected == 1 events per object\n",
    "    #detected == 1 means that the signal is significantly\n",
    "    #different than the background flux\n",
    "    #using same loop to plot distribution of best period\n",
    "    best_periods = []\n",
    "    best_scores = []\n",
    "    detecteds = []\n",
    "    \n",
    "    for x in ids:\n",
    "        xseries = train_series[(train_series['object_id'] == x)]\n",
    "        detectedx = xseries[['detected']]\n",
    "        detecteds += [int(detectedx.sum())]\n",
    "        model, best_period, best_score = fit_multiband(x)\n",
    "        best_periods += [best_period]\n",
    "        best_scores += [best_score]\n",
    "        \n",
    "    \n",
    "    #create histogram from detecteds\n",
    "    plt.figure()\n",
    "    plt.hist(detecteds)\n",
    "    plt.title('Frequency of Detected Events: Class {}'.format(target))\n",
    "    plt.xlabel('Number of Detected Events')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    #create histogram from best periods\n",
    "    plt.figure()\n",
    "    plt.hist(best_periods)\n",
    "    plt.title('Distribution of Best Period: Class {}'.format(target))\n",
    "    plt.xlabel('Period')\n",
    "    plt.ylabel('Occurrences')\n",
    "    avg_best_score = np.mean(best_scores)\n",
    "    \n",
    "    #naive benchmark for whether events tend to occur within or beyond our galaxy\n",
    "    hostgal = metaseries[['hostgal_specz']]\n",
    "    \n",
    "    #check if 'hostgal_specz' has any zero component\n",
    "        #if so, such events can occur within galaxy\n",
    "    within_galaxy_possible = (0 in hostgal.values)\n",
    "    #check if 'hostgal_specz' has all zero components\n",
    "        #if so, such events exclusively occur within the galaxy\n",
    "    within_galaxy_must = (hostgal.values == 0).all()\n",
    "    \n",
    "    #ts_analysis = ts_by_target(target)\n",
    "    wav_analysis = wav_by_target(target)\n",
    "    \n",
    "    return (wav_analysis, within_galaxy_possible, within_galaxy_must, avg_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_analysis(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_analysis(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_analysis(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_analysis(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_analysis(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_analysis(62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_analysis(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_analysis(92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_analysis(67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_analysis(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_analysis(95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_analysis(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_analysis(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_analysis(53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
